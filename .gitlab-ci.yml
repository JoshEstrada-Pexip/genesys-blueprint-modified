cache:
  paths:
    - work/node_modules
    - cache/dev
    - cache/main

.base:
  tags:
    - genesys
    - readonly

.base-node:
  image: node:14.19.0 # change to match your node version
  extends:
    - .base
  before_script:
    - ls -a
    - ls -a public
    - mkdir -p work
    - shopt -s extglob dotglob
    - mv !(work|cache) work
    - mkdir -p cache
    - mkdir -p public
    - cp -RT cache public
    - ls
    - ls -a cache
    - ls -a public
    - cd work
    - echo "//gitlab.com/api/v4/projects/24337530/packages/npm/:_authToken=${CI_JOB_TOKEN}" >> .npmrc
    - npm install
    - npm run postinstall
    - ls -a
    - ls -a public

build:
  stage: build
  extends:
    - .base-node
  script:
    - CI=false npm run build
  artifacts:
    name: build
    paths:
      - work/build/
    expire_in: '900'


test:
  stage: test
  extends:
    - .base-node
  script:
   - CI=true npm test

lint:
  stage: test
  extends:
    - .base-node
  script:
    - npm run lint

.bucket-upload:
  extends:
    - .base
  tags: # use the protected runner to get access to upload service accounts
    - genesys
    - protected
  dependencies:
    - build
  image: eu.gcr.io/px-service-ci-gcr/pexdeploy:latest
  script:
    - cd work/build
    - ls
    # Default caching is 1 hour
    - gcloud storage cp robots.txt gs://$BUCKET
    - gcloud storage cp orange-circle-loader.gif gs://$BUCKET
    # Do the following need hashes/versioning? could break if relying on changes yet cached version of file used
    - gcloud storage cp -r locales gs://$BUCKET
    - gcloud storage cp -r media-processor gs://$BUCKET
    - gcloud storage cp -r selfie_segmentation gs://$BUCKET
    # Each file in static contains hash so give a year caching
    - gcloud storage cp --cache-control="public, max-age=31536000" -r static gs://$BUCKET
    # Copy main last to ensure all required files already uploaded
    - gcloud storage cp --cache-control="public, max-age=600" index.html gs://$BUCKET

staging-bucket-upload:
  stage: deploy
  rules:
    - if: $CI_COMMIT_BRANCH == "dev" && $CI_PIPELINE_SOURCE == "push"
  extends:
    - .bucket-upload
  environment: staging-bucket-upload
  variables:
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: px-service-staging-genesys-upload
    BUCKET: genesys-metal-appliance-329611

prod-bucket-upload:
  stage: deploy
  rules:
    - if: $CI_COMMIT_BRANCH == "main" && $CI_PIPELINE_SOURCE == "push"
  extends:
    - .bucket-upload
  environment: prod-bucket-upload
  variables:
    KUBERNETES_SERVICE_ACCOUNT_OVERWRITE: px-service-prod-genesys-upload
    BUCKET: genesys-complete-tube-329611
